{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_VERSION = \"02\"\n",
    "NUM_TIMESTEPS = 28\n",
    "RUN_ON_SAMPLE = False\n",
    "SAMPLE_SIZE = 500\n",
    "SCALING = False\n",
    "\n",
    "DROPOUT = 0.3\n",
    "MIN_LR = 1e-4\n",
    "MAX_LR = 1e-2\n",
    "STEP_SIZE = 2\n",
    "BATCH_SIZE = 10*1024\n",
    "PREDICT_BATCH_SIZE = 20*1024\n",
    "NUM_EPOCHS = [4, 28, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime, pickle, gc\n",
    "from time import time, ctime\n",
    "from pprint import pprint\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, LSTM, Embedding, Dense, concatenate, TimeDistributed\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout, Flatten, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import RepeatVector, Lambda\n",
    "from tensorflow.keras.backend import repeat_elements\n",
    "from tensorflow.keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.optimizers import TriangularCyclicalLearningRate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeded_value = 88888\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "np.random.seed(seeded_value)\n",
    "tf.random.set_seed(seeded_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppress scientific notation\n",
    "pd.options.display.precision = 2\n",
    "np.set_printoptions(suppress=True)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.2.0']\n"
     ]
    }
   ],
   "source": [
    "print([\n",
    "    tf.__version__\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 25 19:17:18 2020\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "start = datetime.now()\n",
    "print(ctime(start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files\n",
    "1. calendar.csv - Contains information about the dates on which the products are sold.\n",
    "2. sales_train_validation.csv - Contains the historical daily unit sales data per product and store [d_1 - d_1913]\n",
    "3. sample_submission.csv - The correct format for submissions. Reference the Evaluation tab for more info.\n",
    "4. sell_prices.csv - Contains information about the price of the products sold per store and date.\n",
    "5. sales_train_evaluation.csv - Includes sales [d_1 - d_1941] (labels used for the Public leaderboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"../data/\"\n",
    "RESULTS_DIR = \"../results/\"\n",
    "PICKLE_DIR = \"../data/preprocessed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CARDINAL_VARS = ['state_id', 'store_id', 'cat_id', 'dept_id', 'item_id', 'id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_INDICES = np.arange(1, 1885 + 1) # Could use 1156 i.e. only 2 years of data\n",
    "VALID_INDICES = np.arange(1886, 1913 + 1)\n",
    "PUBLIC_INDICES = np.arange(1914, 1941 + 1)\n",
    "PRIVATE_INDICES = np.arange(1942, 1969 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1885 1885\n",
      "1886 1913 28\n",
      "1914 1941 28\n",
      "1942 1969 28\n"
     ]
    }
   ],
   "source": [
    "print(min(TRAIN_INDICES), max(TRAIN_INDICES), len(TRAIN_INDICES))\n",
    "print(min(VALID_INDICES), max(VALID_INDICES), len(VALID_INDICES))\n",
    "print(min(PUBLIC_INDICES), max(PUBLIC_INDICES), len(PUBLIC_INDICES))\n",
    "print(min(PRIVATE_INDICES), max(PRIVATE_INDICES), len(PRIVATE_INDICES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about memory management in pandas [here](https://pythonspeed.com/articles/pandas-load-less-data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(infer_mode:bool=False):\n",
    "    print('Reading files...')\n",
    "    \n",
    "    calendar = pd.read_csv('../data/calendar.csv').fillna(\"None\")\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    print('Calendar has {} rows and {} columns'.format(calendar.shape[0], calendar.shape[1]))\n",
    "    \n",
    "    sell_prices = pd.read_csv('../data/sell_prices.csv')\n",
    "    sell_prices = reduce_mem_usage(sell_prices)\n",
    "    print('Sell prices has {} rows and {} columns'.format(sell_prices.shape[0], sell_prices.shape[1]))\n",
    "    \n",
    "    sales = pd.read_csv('../data/sales_train_evaluation.csv')\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales.shape[0], sales.shape[1]))\n",
    "    sales[['d_'+str(i) for i in PRIVATE_INDICES]] = pd.DataFrame(np.zeros(shape=(sales.shape[0], len(PRIVATE_INDICES))))\n",
    "    print('Sales train validation has {} rows and {} columns'.format(sales.shape[0], sales.shape[1]))\n",
    "    \n",
    "    submission = pd.read_csv('../data/sample_submission.csv')\n",
    "    \n",
    "    pprint({\n",
    "        \"calendar.shape\" : calendar.shape,\n",
    "        \"sell_prices.shape\" : sell_prices.shape,\n",
    "        \"sales.shape\" : sales.shape,\n",
    "        \"submission.shape\" : submission.shape\n",
    "    })\n",
    "    \n",
    "    return calendar, sell_prices, sales, submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dateparts(calendar, datecolname):\n",
    "    calendar[\"Date\"] = pd.to_datetime(calendar[datecolname], format = (\"%Y-%m-%d\"))\n",
    "    calendar[\"Year\"] = calendar[\"Date\"].dt.year.astype('int16')\n",
    "    calendar[\"Quarter\"] = calendar[\"Date\"].dt.quarter\n",
    "    calendar[\"Month\"] = calendar[\"Date\"].dt.month\n",
    "    calendar[\"Week\"] = calendar[\"Date\"].dt.week\n",
    "    calendar[\"Day\"] = calendar[\"Date\"].dt.day\n",
    "    calendar[\"DOW\"] = calendar[\"Date\"].dt.dayofweek\n",
    "    calendar = reduce_mem_usage(calendar)\n",
    "    return calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melt_join_fill(sales, calendar, sell_prices):\n",
    "    if RUN_ON_SAMPLE:\n",
    "        sales = pd.melt(sales.sample(SAMPLE_SIZE),\n",
    "                        id_vars=CARDINAL_VARS,\n",
    "                        value_vars=Y_VARS,\n",
    "                        var_name=\"day_id\",\n",
    "                        value_name='demand')\n",
    "    else:\n",
    "        sales = pd.melt(sales,\n",
    "                        id_vars=CARDINAL_VARS,\n",
    "                        value_vars=Y_VARS,\n",
    "                        var_name=\"day_id\",\n",
    "                        value_name='demand')\n",
    "    print(\"[INFO] \", \"Melting  -- COMPLETE\", ctime(time()))\n",
    "\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    sales = pd.merge(sales, calendar, how=\"left\", left_on=\"day_id\", right_on=\"d\")\n",
    "    print(\"[INFO] \", \"Merging1 -- COMPLETE\", ctime(time()))\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    sales = pd.merge(sales, sell_prices, how=\"left\", on=[\"wm_yr_wk\", \"store_id\", \"item_id\"])\n",
    "    print(\"[INFO] \", \"Merging2 -- COMPLETE\", ctime(time()))\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    # if sell_price is NA\n",
    "    sales = sales.sort_values(by=CARDINAL_VARS+[\"date\"])\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    sales[\"sell_price_available\"] = np.where(sales.sell_price.isna(), \"N\", \"Y\")\n",
    "    sales[[\"sell_price\"]] = sales.groupby([\"item_id\"])[[\"sell_price\"]].ffill()\n",
    "    sales[[\"sell_price\"]] = sales.groupby([\"item_id\"])[[\"sell_price\"]].bfill()\n",
    "    sales = sales.drop([\"d\", \"wday\", 'date', 'wm_yr_wk', 'weekday', 'month', 'year'], axis=1)\n",
    "    \n",
    "    sales['day_id'] = sales['day_id'].astype(str).apply(lambda x: x[2:]).astype(np.int16)\n",
    "    \n",
    "    print(\"[INFO] \", \"Imputing -- COMPLETE\", ctime(time()))    \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    sales['weights'] = sales[\"sell_price\"] * sales[\"demand\"]\n",
    "    sales['rolling_weights'] = sales.groupby(CARDINAL_VARS)['weights'].rolling(window=NUM_TIMESTEPS, min_periods=1).sum().reset_index(drop=True)\n",
    "    \n",
    "    sales['weights'] = sales['weights'].apply(lambda x: np.max((1.0, x)))\n",
    "    sales['rolling_weights'] = sales['rolling_weights'].apply(lambda x: np.max((1.0, x)))\n",
    "    \n",
    "    print(\"[INFO] \", \"Weighting -- COMPLETE\", ctime(time()))    \n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    print(\"[INFO] \", \"Final dataset contains\", sales.shape)\n",
    "    \n",
    "    return sales.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading files...\n",
      "Mem. usage decreased to  0.12 Mb (41.9% reduction)\n",
      "Calendar has 1969 rows and 14 columns\n",
      "Mem. usage decreased to 130.48 Mb (37.5% reduction)\n",
      "Sell prices has 6841121 rows and 4 columns\n",
      "Sales train validation has 30490 rows and 1947 columns\n",
      "{'calendar.shape': (1969, 14),\n",
      " 'sales.shape': (30490, 1975),\n",
      " 'sell_prices.shape': (6841121, 4),\n",
      " 'submission.shape': (60980, 29)}\n",
      "Mem. usage decreased to  0.15 Mb (30.4% reduction)\n",
      "[INFO]  Melting  -- COMPLETE Thu Jun 25 19:17:38 2020\n",
      "[INFO]  Merging1 -- COMPLETE Thu Jun 25 19:18:00 2020\n",
      "[INFO]  Merging2 -- COMPLETE Thu Jun 25 19:18:38 2020\n",
      "[INFO]  Imputing -- COMPLETE Thu Jun 25 19:21:07 2020\n",
      "[INFO]  Weighting -- COMPLETE Thu Jun 25 19:37:15 2020\n",
      "[INFO]  Final dataset contains (60034810, 26)\n",
      "Saving all data to --->  ../data/preprocessed/\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(PICKLE_DIR+\"merged_df.pickle\"):\n",
    "    \n",
    "    calendar, sell_prices, sales, submission = read_data()\n",
    "    \n",
    "    calendar = add_dateparts(calendar, \"date\")\n",
    "    \n",
    "    Y_VARS = sales.columns[sales.columns.str.startswith(\"d_\")]\n",
    "\n",
    "    data = melt_join_fill(sales, calendar, sell_prices)\n",
    "    \n",
    "    del sales, calendar, sell_prices\n",
    "    gc.collect()\n",
    "\n",
    "    print(\"Saving all data to ---> \", PICKLE_DIR)\n",
    "    with open(os.path.join(PICKLE_DIR, \"merged_df.pickle\"),\"wb\") as f:\n",
    "        pickle.dump((data), f)\n",
    "else:\n",
    "    print(\"Pickle exists hence loading from pickle file ---> \", PICKLE_DIR)\n",
    "    with open(os.path.join(PICKLE_DIR+\"merged_df.pickle\"), \"rb\") as f:\n",
    "        data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1885, 1913, 1941, 1969)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1913-28, 1913, 1913 + 28, 1913 + 28 + 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2011-01-29 00:00:00'), Timestamp('2016-06-19 00:00:00'))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Date.min(), data.Date.max()#, data.Date.max() + 28, data.Date.max() + 28 + 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60034810, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>id</th>\n",
       "      <th>day_id</th>\n",
       "      <th>demand</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>...</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week</th>\n",
       "      <th>Day</th>\n",
       "      <th>DOW</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>sell_price_available</th>\n",
       "      <th>weights</th>\n",
       "      <th>rolling_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>6.00</td>\n",
       "      <td>33.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.00</td>\n",
       "      <td>296.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.00</td>\n",
       "      <td>76.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>2.00</td>\n",
       "      <td>85.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>FOODS_1</td>\n",
       "      <td>FOODS_1_001</td>\n",
       "      <td>FOODS_1_001_CA_1_evaluation</td>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.00</td>\n",
       "      <td>Y</td>\n",
       "      <td>8.00</td>\n",
       "      <td>85.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_id store_id cat_id  dept_id      item_id                           id  \\\n",
       "0       CA     CA_1  FOODS  FOODS_1  FOODS_1_001  FOODS_1_001_CA_1_evaluation   \n",
       "1       CA     CA_1  FOODS  FOODS_1  FOODS_1_001  FOODS_1_001_CA_1_evaluation   \n",
       "2       CA     CA_1  FOODS  FOODS_1  FOODS_1_001  FOODS_1_001_CA_1_evaluation   \n",
       "3       CA     CA_1  FOODS  FOODS_1  FOODS_1_001  FOODS_1_001_CA_1_evaluation   \n",
       "4       CA     CA_1  FOODS  FOODS_1  FOODS_1_001  FOODS_1_001_CA_1_evaluation   \n",
       "\n",
       "   day_id  demand event_name_1 event_type_1  ...  Year Quarter  Month  Week  \\\n",
       "0       1    3.00         None         None  ...  2011       1      1     4   \n",
       "1       2    0.00         None         None  ...  2011       1      1     4   \n",
       "2       3    0.00         None         None  ...  2011       1      1     5   \n",
       "3       4    1.00         None         None  ...  2011       1      2     5   \n",
       "4       5    4.00         None         None  ...  2011       1      2     5   \n",
       "\n",
       "   Day DOW  sell_price  sell_price_available  weights  rolling_weights  \n",
       "0   29   5        2.00                     Y     6.00            33.60  \n",
       "1   30   6        2.00                     Y     1.00           296.93  \n",
       "2   31   0        2.00                     Y     1.00            76.73  \n",
       "3    1   1        2.00                     Y     2.00            85.01  \n",
       "4    2   2        2.00                     Y     8.00            85.75  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape); data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONT_VARS = ['snap_CA', 'snap_TX', 'snap_WI', 'sell_price']\n",
    "CAT_VARS = ['state_id', 'store_id', 'cat_id', 'dept_id', 'item_id', 'event_name_1',\n",
    "            'event_type_1', 'event_name_2', 'event_type_2', 'Year', 'Quarter',\n",
    "            'Month', 'Week', 'Day', 'DOW', 'sell_price_available']\n",
    "DEP_VAR = ['demand']\n",
    "WEIGHT_VAR = ['weights', 'rolling_weights']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Category_Mapping = {}\n",
    "for c in CAT_VARS:\n",
    "    # convert columns to categories\n",
    "    data[c+\"_cat\"] = data[c].astype(\"category\")\n",
    "    \n",
    "    # save the mapping for later use\n",
    "    Category_Mapping.update({c+\"_cat\" : dict(enumerate(data[c+\"_cat\"].cat.categories))})\n",
    "    \n",
    "    # Copy categories as integer codes\n",
    "    data[c+\"_cat\"] = data[c+\"_cat\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DOW_cat': {'emb_sz': 3, 'max': 6, 'min': 0, 'nuniq': 7},\n",
      " 'Day_cat': {'emb_sz': 10, 'max': 30, 'min': 0, 'nuniq': 31},\n",
      " 'Month_cat': {'emb_sz': 6, 'max': 11, 'min': 0, 'nuniq': 12},\n",
      " 'Quarter_cat': {'emb_sz': 2, 'max': 3, 'min': 0, 'nuniq': 4},\n",
      " 'Week_cat': {'emb_sz': 10, 'max': 52, 'min': 0, 'nuniq': 53},\n",
      " 'Year_cat': {'emb_sz': 3, 'max': 5, 'min': 0, 'nuniq': 6},\n",
      " 'cat_id_cat': {'emb_sz': 2, 'max': 2, 'min': 0, 'nuniq': 3},\n",
      " 'dept_id_cat': {'emb_sz': 3, 'max': 6, 'min': 0, 'nuniq': 7},\n",
      " 'event_name_1_cat': {'emb_sz': 10, 'max': 30, 'min': 0, 'nuniq': 31},\n",
      " 'event_name_2_cat': {'emb_sz': 2, 'max': 4, 'min': 0, 'nuniq': 5},\n",
      " 'event_type_1_cat': {'emb_sz': 2, 'max': 4, 'min': 0, 'nuniq': 5},\n",
      " 'event_type_2_cat': {'emb_sz': 2, 'max': 2, 'min': 0, 'nuniq': 3},\n",
      " 'item_id_cat': {'emb_sz': 10, 'max': 3048, 'min': 0, 'nuniq': 3049},\n",
      " 'sell_price_available_cat': {'emb_sz': 2, 'max': 1, 'min': 0, 'nuniq': 2},\n",
      " 'state_id_cat': {'emb_sz': 2, 'max': 2, 'min': 0, 'nuniq': 3},\n",
      " 'store_id_cat': {'emb_sz': 5, 'max': 9, 'min': 0, 'nuniq': 10}}\n"
     ]
    }
   ],
   "source": [
    "Unique_Dict ={}\n",
    "for c in CAT_VARS:\n",
    "    col = c+\"_cat\"\n",
    "    Unique_Dict.update({col:{'min':data[col].min(), \n",
    "                             'max':data[col].max(), \n",
    "                             'nuniq':data[col].nunique(), \n",
    "                             'emb_sz':max(min(int(data[col].nunique() / 2), 10), 2)}})\n",
    "pprint(Unique_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_CAT_VARS = [col+\"_cat\" for col in CAT_VARS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALING:\n",
    "    MMS = MinMaxScaler()\n",
    "    data[CONT_VARS] = MMS.fit_transform(data[CONT_VARS])\n",
    "\n",
    "    MMS_Y = MinMaxScaler(feature_range=(0, 0.8))\n",
    "    data[DEP_VAR] = MMS_Y.fit_transform(data[DEP_VAR])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['set'] = np.where(data.day_id.isin(TRAIN_INDICES), \"Train\",\n",
    "                       np.where(data.day_id.isin(VALID_INDICES), \"Valid\",\n",
    "                                np.where(data.day_id.isin(PUBLIC_INDICES), \"Public\", \"Private\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">day_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>amin</th>\n",
       "      <th>amax</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>set</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Private</th>\n",
       "      <td>853720</td>\n",
       "      <td>1942</td>\n",
       "      <td>1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Public</th>\n",
       "      <td>853720</td>\n",
       "      <td>1914</td>\n",
       "      <td>1941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>57473650</td>\n",
       "      <td>1</td>\n",
       "      <td>1885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Valid</th>\n",
       "      <td>853720</td>\n",
       "      <td>1886</td>\n",
       "      <td>1913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id day_id      \n",
       "            count   amin  amax\n",
       "set                           \n",
       "Private    853720   1942  1969\n",
       "Public     853720   1914  1941\n",
       "Train    57473650      1  1885\n",
       "Valid      853720   1886  1913"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('set').agg({\n",
    "    'id':'count',\n",
    "    'day_id':[np.min, np.max]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((57473650, 43), (853720, 43), (853720, 43), (853720, 43))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.loc[data.day_id.isin(TRAIN_INDICES)]\n",
    "valid_data = data.loc[data.day_id.isin(VALID_INDICES)]\n",
    "public_data = data.loc[data.day_id.isin(PUBLIC_INDICES)]\n",
    "private_data = data.loc[data.day_id.isin(PRIVATE_INDICES)]\n",
    "train_data.shape, valid_data.shape, public_data.shape, private_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[0] == train_data.shape[0] + valid_data.shape[0] + private_data.shape[0] + private_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 25 19:39:44 2020\n"
     ]
    }
   ],
   "source": [
    "model_time = time()\n",
    "model_t = datetime.now()\n",
    "print(ctime(model_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    layers = []\n",
    "    inputs = []\n",
    "    for i,col in enumerate(CAT_VARS):\n",
    "        input_ = Input(shape=1, name=col+\"_cat\")\n",
    "        embedding =  Embedding(Unique_Dict[col+\"_cat\"]['nuniq'],\n",
    "                               Unique_Dict[col+\"_cat\"]['emb_sz'],\n",
    "                               name='emb_'+col)(input_)\n",
    "        vec = Flatten()(embedding)\n",
    "        layers.append(vec)\n",
    "        inputs.append(input_)\n",
    "    \n",
    "    for i, col in enumerate(CONT_VARS):\n",
    "        input_ = Input(shape=1, name=col)\n",
    "        layers.append(input_)\n",
    "        inputs.append(input_)\n",
    "    \n",
    "    concat_layer = concatenate(layers)\n",
    "    x = Dense(2048)(concat_layer)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(1024)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Dense(512)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(256)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(128)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Dense(32)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    if SCALING:\n",
    "        demand = Dense(1, activation='sigmoid', name='demand')(x)\n",
    "    else:\n",
    "        demand = Dense(1, activation='relu', name='demand')(x)\n",
    "    \n",
    "    model = Model(inputs, demand)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "state_id_cat (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "store_id_cat (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cat_id_cat (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dept_id_cat (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_cat (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_name_1_cat (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_type_1_cat (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_name_2_cat (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "event_type_2_cat (InputLayer)   [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Year_cat (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Quarter_cat (InputLayer)        [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Month_cat (InputLayer)          [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Week_cat (InputLayer)           [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Day_cat (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "DOW_cat (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sell_price_available_cat (Input [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "emb_state_id (Embedding)        (None, 1, 2)         6           state_id_cat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "emb_store_id (Embedding)        (None, 1, 5)         50          store_id_cat[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "emb_cat_id (Embedding)          (None, 1, 2)         6           cat_id_cat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "emb_dept_id (Embedding)         (None, 1, 3)         21          dept_id_cat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "emb_item_id (Embedding)         (None, 1, 10)        30490       item_id_cat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "emb_event_name_1 (Embedding)    (None, 1, 10)        310         event_name_1_cat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "emb_event_type_1 (Embedding)    (None, 1, 2)         10          event_type_1_cat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "emb_event_name_2 (Embedding)    (None, 1, 2)         10          event_name_2_cat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "emb_event_type_2 (Embedding)    (None, 1, 2)         6           event_type_2_cat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "emb_Year (Embedding)            (None, 1, 3)         18          Year_cat[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "emb_Quarter (Embedding)         (None, 1, 2)         8           Quarter_cat[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "emb_Month (Embedding)           (None, 1, 6)         72          Month_cat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "emb_Week (Embedding)            (None, 1, 10)        530         Week_cat[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "emb_Day (Embedding)             (None, 1, 10)        310         Day_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "emb_DOW (Embedding)             (None, 1, 3)         21          DOW_cat[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "emb_sell_price_available (Embed (None, 1, 2)         4           sell_price_available_cat[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2)            0           emb_state_id[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5)            0           emb_store_id[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2)            0           emb_cat_id[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 3)            0           emb_dept_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 10)           0           emb_item_id[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 10)           0           emb_event_name_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 2)            0           emb_event_type_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 2)            0           emb_event_name_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 2)            0           emb_event_type_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 3)            0           emb_Year[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 2)            0           emb_Quarter[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 6)            0           emb_Month[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 10)           0           emb_Week[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_13 (Flatten)            (None, 10)           0           emb_Day[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_14 (Flatten)            (None, 3)            0           emb_DOW[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_15 (Flatten)            (None, 2)            0           emb_sell_price_available[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "snap_CA (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "snap_TX (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "snap_WI (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sell_price (InputLayer)         [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 78)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "                                                                 flatten_4[0][0]                  \n",
      "                                                                 flatten_5[0][0]                  \n",
      "                                                                 flatten_6[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "                                                                 flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_10[0][0]                 \n",
      "                                                                 flatten_11[0][0]                 \n",
      "                                                                 flatten_12[0][0]                 \n",
      "                                                                 flatten_13[0][0]                 \n",
      "                                                                 flatten_14[0][0]                 \n",
      "                                                                 flatten_15[0][0]                 \n",
      "                                                                 snap_CA[0][0]                    \n",
      "                                                                 snap_TX[0][0]                    \n",
      "                                                                 snap_WI[0][0]                    \n",
      "                                                                 sell_price[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2048)         161792      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 2048)         8192        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 2048)         0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 2048)         0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         2098176     activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 1024)         4096        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1024)         0           dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          524800      activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 512)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512)          0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 128)          32896       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64)           8256        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64)           256         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 64)           0           dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32)           2080        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32)           128         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "demand (Dense)                  (None, 1)            33          activation_6[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,007,489\n",
      "Trainable params: 2,999,361\n",
      "Non-trainable params: 8,128\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\"):\n",
    "    model.load_weights(RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclr = TriangularCyclicalLearningRate(\n",
    "    initial_learning_rate=MIN_LR,\n",
    "    maximal_learning_rate=MAX_LR,\n",
    "    step_size=STEP_SIZE * len(train_data)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = ModelCheckpoint(filepath=RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\", monitor='val_loss',\n",
    "                      verbose=0, save_best_only=True, save_weights_only=False, mode='min', save_freq='epoch')\n",
    "csvl = CSVLogger(filename=RESULTS_DIR+\"LossLogs_\"+MODEL_VERSION+\".csv\",\n",
    "                 separator=\",\", append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MAX_LR)\n",
    "model.compile(loss='mse', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "5613/5613 [==============================] - 912s 163ms/step - loss: 751.9243 - val_loss: 395.4288\n",
      "Epoch 2/4\n",
      "5613/5613 [==============================] - 910s 162ms/step - loss: 668.9698 - val_loss: 385.4682\n",
      "Epoch 3/4\n",
      "5613/5613 [==============================] - 905s 161ms/step - loss: 622.7936 - val_loss: 368.3672\n",
      "Epoch 4/4\n",
      "5613/5613 [==============================] - 902s 161ms/step - loss: 596.9969 - val_loss: 367.5995\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                    y=train_data[DEP_VAR].to_dict(orient='series'),\n",
    "                    validation_data=(valid_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                                     valid_data[DEP_VAR].to_dict(orient='series'),\n",
    "                                     valid_data[WEIGHT_VAR].to_dict(orient='series')['rolling_weights']\n",
    "                                    ),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[0],\n",
    "                    shuffle=True,\n",
    "                    verbose=1,\n",
    "                    sample_weight=train_data[WEIGHT_VAR].to_dict(orient='series')['rolling_weights'],\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric_names = ['loss']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(filepath=RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=tclr)\n",
    "model.compile(loss='mse', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "5613/5613 [==============================] - 901s 161ms/step - loss: 553.1205 - val_loss: 365.3135\n",
      "Epoch 2/28\n",
      "5613/5613 [==============================] - 901s 160ms/step - loss: 544.7419 - val_loss: 363.1245\n",
      "Epoch 3/28\n",
      "5613/5613 [==============================] - 901s 161ms/step - loss: 531.2322 - val_loss: 360.7960\n",
      "Epoch 4/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 519.8090 - val_loss: 358.7242\n",
      "Epoch 5/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 537.7463 - val_loss: 358.2088\n",
      "Epoch 6/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 535.6622 - val_loss: 357.3051\n",
      "Epoch 7/28\n",
      "5613/5613 [==============================] - 901s 160ms/step - loss: 534.1042 - val_loss: 356.6457\n",
      "Epoch 8/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 532.1493 - val_loss: 355.9770\n",
      "Epoch 9/28\n",
      "5613/5613 [==============================] - 901s 160ms/step - loss: 531.7778 - val_loss: 355.0615\n",
      "Epoch 10/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 530.8359 - val_loss: 354.7912\n",
      "Epoch 11/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 531.5102 - val_loss: 354.5897\n",
      "Epoch 12/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 529.4172 - val_loss: 353.7027\n",
      "Epoch 13/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 528.5904 - val_loss: 353.6442\n",
      "Epoch 14/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 525.1592 - val_loss: 353.4436\n",
      "Epoch 15/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 523.2695 - val_loss: 353.1962\n",
      "Epoch 16/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 525.7416 - val_loss: 353.0967\n",
      "Epoch 17/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 521.8402 - val_loss: 352.9190\n",
      "Epoch 18/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 522.7495 - val_loss: 353.0804\n",
      "Epoch 19/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 521.6547 - val_loss: 353.3147\n",
      "Epoch 20/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 520.0933 - val_loss: 352.4029\n",
      "Epoch 21/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 517.5148 - val_loss: 352.2571\n",
      "Epoch 22/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 519.8986 - val_loss: 352.1725\n",
      "Epoch 23/28\n",
      "5613/5613 [==============================] - 901s 160ms/step - loss: 518.7487 - val_loss: 351.8038\n",
      "Epoch 24/28\n",
      "5613/5613 [==============================] - 900s 160ms/step - loss: 516.9254 - val_loss: 351.6868\n",
      "Epoch 25/28\n",
      " 577/5613 [==>...........................] - ETA: 13:23 - loss: 529.6548"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                    y=train_data[DEP_VAR].to_dict(orient='series'),\n",
    "                    validation_data=(valid_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                                     valid_data[DEP_VAR].to_dict(orient='series'),\n",
    "                                     valid_data[WEIGHT_VAR].to_dict(orient='series')['rolling_weights']\n",
    "                                    ),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[1],\n",
    "                    shuffle=True,\n",
    "                    verbose=1, \n",
    "                    sample_weight=train_data[WEIGHT_VAR].to_dict(orient='series')['rolling_weights'],\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_names = ['loss']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model ' + i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(filepath=RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(learning_rate=MIN_LR*0.1)\n",
    "model.compile(loss='mse', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                    y=train_data[DEP_VAR].to_dict(orient='series'),\n",
    "                    validation_data=(valid_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                                     valid_data[DEP_VAR].to_dict(orient='series'),\n",
    "                                     valid_data[WEIGHT_VAR].to_dict(orient='series')['rolling_weights']\n",
    "                                    ),\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS[2],\n",
    "                    shuffle=True,\n",
    "                    verbose=1, \n",
    "                    sample_weight=train_data[WEIGHT_VAR].to_dict(orient='series')['rolling_weights'],\n",
    "                    callbacks=[mcp, csvl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metric_names = ['loss']\n",
    "\n",
    "for i, j in zip(metric_names, ['val_'+i for i in metric_names]):\n",
    "    plt.plot(history.history[i])\n",
    "    plt.plot(history.history[j])\n",
    "    plt.title('Model '+i)\n",
    "    plt.ylabel(i.upper())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(filepath=RESULTS_DIR+\"FinalCheckpoint_\"+MODEL_VERSION+\".h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\"):\n",
    "    model = tf.keras.models.load_model(filepath=RESULTS_DIR+\"BestCheckpoint_\"+MODEL_VERSION+\".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = model.predict(train_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                            batch_size=PREDICT_BATCH_SIZE, verbose=1)\n",
    "\n",
    "valid_preds = model.predict(valid_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                            batch_size=PREDICT_BATCH_SIZE, verbose=1)\n",
    "\n",
    "public_preds = model.predict(public_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                             batch_size=PREDICT_BATCH_SIZE, verbose=1)\n",
    "\n",
    "private_preds = model.predict(private_data[NEW_CAT_VARS + CONT_VARS].to_dict(orient='series'),\n",
    "                              batch_size=PREDICT_BATCH_SIZE, verbose=1)\n",
    "\n",
    "print(train_preds.shape, valid_preds.shape, public_preds.shape, private_preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SCALING:\n",
    "    train_demand = MMS_Y.inverse_transform(train_preds)\n",
    "    valid_demand = MMS_Y.inverse_transform(valid_preds)\n",
    "    public_demand = MMS_Y.inverse_transform(public_preds)\n",
    "    private_demand = MMS_Y.inverse_transform(private_preds)\n",
    "    \n",
    "    data['prediction'] = 0\n",
    "    data[['prediction']].loc[data.day_id.isin(TRAIN_INDICES)] = train_preds\n",
    "    data[['prediction']].loc[data.day_id.isin(VALID_INDICES)] = valid_preds\n",
    "    data[['prediction']].loc[data.day_id.isin(PUBLIC_INDICES)] = public_preds\n",
    "    data[['prediction']].loc[data.day_id.isin(PRIVATE_INDICES)] = private_preds\n",
    "\n",
    "    data['demand_Unscaled'] = MMS_Y.inverse_transform(data[['demand']])\n",
    "    data[[col+'_Unscaled' for col in CONT_VARS]] = pd.DataFrame(MMS.inverse_transform(data[CONT_VARS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pred_demand'] = 0\n",
    "\n",
    "if SCALING:\n",
    "    data['pred_demand'].loc[data.day_id.isin(TRAIN_INDICES)] = train_demand.flatten()\n",
    "    data['pred_demand'].loc[data.day_id.isin(VALID_INDICES)] = valid_demand.flatten()\n",
    "    data['pred_demand'].loc[data.day_id.isin(PUBLIC_INDICES)] = public_demand.flatten()\n",
    "    data['pred_demand'].loc[data.day_id.isin(PRIVATE_INDICES)] = private_demand.flatten()\n",
    "else:\n",
    "    data['pred_demand'].loc[data.day_id.isin(TRAIN_INDICES)] = train_preds.flatten()\n",
    "    data['pred_demand'].loc[data.day_id.isin(VALID_INDICES)] = valid_preds.flatten()\n",
    "    data['pred_demand'].loc[data.day_id.isin(PUBLIC_INDICES)] = public_preds.flatten()\n",
    "    data['pred_demand'].loc[data.day_id.isin(PRIVATE_INDICES)] = private_preds.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['Train', 'Valid', 'Public', 'Private']:\n",
    "    print(i)\n",
    "    print('\\t',{\n",
    "        i+'_RMSE' : np.round(mean_squared_error(y_true = data['demand'].loc[data.set == i],\n",
    "                                                y_pred = data['pred_demand'].loc[data.set == i]),\n",
    "                             2) if i!='Private' else 'None',\n",
    "        i+\"_REAL_SUM\" : np.round(data['demand'].loc[data.set != i].sum(), 2),\n",
    "        i+\"_PRED_SUM\" : np.round(data['pred_demand'].loc[data.set != i].sum(), 2),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is the distribution same?\n",
    "data[['demand','pred_demand','set']].groupby('set').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = data.loc[data['set'].isin(['Private', 'Public'])][['id',\n",
    "                                                                'day_id',\n",
    "                                                                'pred_demand', \n",
    "                                                                'set']].copy().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['day_id2'] = 'F' + pd.Series(np.where(submission['day_id']<=max(PUBLIC_INDICES), \n",
    "                                                 submission['day_id'] - min(PUBLIC_INDICES) + 1, \n",
    "                                                 submission['day_id'] - min(PRIVATE_INDICES) + 1).astype(int).astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['id'] = np.where(submission['set']==\"Public\",\n",
    "                            submission['id'].str.replace(\"evaluation\", \"validation\"), \n",
    "                            submission['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.groupby('set').agg({\n",
    "    'day_id':[np.min, np.max]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = submission.pivot(\n",
    "    values='pred_demand',\n",
    "    index='id',\n",
    "    columns='day_id2').reset_index(drop=False)\n",
    "submission_file = submission_file[['id']+[\"F\"+str(i) for i in range(1,29,1)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file.to_csv('../results/submission_'+MODEL_VERSION+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time()\n",
    "end = datetime.now()\n",
    "print(ctime(end_time))\n",
    "print(end - start, model_t - start, model_t - end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling is not working... Do it for the whole 2D array instead -- Now it is MinMax 0.1-0.9 Scaling -- No Scaling is Better it seems\n",
    "#### Add weights during training... inside the fit call you need dynamic weighting -- Now both Train and Valid samples are weighted\n",
    "#### Add More Features  -- More features have been added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Conv1D -- Not done yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make use of Dask instead of pandas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
